{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T7 Shield Spatial Analysis Workflows\n",
    "\n",
    "This notebook demonstrates advanced spatial analysis workflows using the T7 Shield GIS environment, specifically focused on Australian forestry and carbon accounting applications.\n",
    "\n",
    "**Author:** T7 Shield GIS Environment  \n",
    "**Created:** 2025  \n",
    "**Purpose:** Professional spatial analysis for forestry projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from pathlib import Path\n",
    "import rasterstats\n",
    "from shapely.geometry import Point, Polygon\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import T7 Shield custom modules\n",
    "import sys\n",
    "sys.path.append('/Volumes/T7 Shield/10_PYTHON_ENVIRONMENT/scripts')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(\"✓ T7 Shield spatial analysis environment ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Area Definition and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up T7 Shield paths\n",
    "t7_base = Path(\"/Volumes/T7 Shield\")\n",
    "reference_data = t7_base / \"01_REFERENCE_DATA\"\n",
    "client_projects = t7_base / \"02_CLIENT_PROJECTS\"\n",
    "\n",
    "def load_project_boundary(project_name: str, boundary_file: str = None):\n",
    "    \"\"\"\n",
    "    Load project boundary from client projects directory.\n",
    "    \n",
    "    Args:\n",
    "        project_name: Name of client project directory\n",
    "        boundary_file: Specific boundary file name (optional)\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame with project boundary\n",
    "    \"\"\"\n",
    "    project_dir = client_projects / project_name\n",
    "    \n",
    "    if boundary_file:\n",
    "        boundary_path = project_dir / boundary_file\n",
    "    else:\n",
    "        # Look for common boundary file patterns\n",
    "        boundary_patterns = ['*boundary*', '*Boundary*', '*.gpkg', '*.shp']\n",
    "        boundary_path = None\n",
    "        \n",
    "        for pattern in boundary_patterns:\n",
    "            matches = list(project_dir.glob(pattern))\n",
    "            if matches:\n",
    "                boundary_path = matches[0]\n",
    "                break\n",
    "    \n",
    "    if boundary_path and boundary_path.exists():\n",
    "        gdf = gpd.read_file(boundary_path)\n",
    "        \n",
    "        # Ensure GDA2020 CRS\n",
    "        if gdf.crs != 'EPSG:7844':\n",
    "            print(f\"Reprojecting from {gdf.crs} to GDA2020 (EPSG:7844)\")\n",
    "            gdf = gdf.to_crs('EPSG:7844')\n",
    "        \n",
    "        # Calculate area in hectares\n",
    "        gdf_albers = gdf.to_crs('EPSG:3577')  # Australian Albers\n",
    "        gdf['area_ha'] = gdf_albers.geometry.area / 10000\n",
    "        \n",
    "        print(f\"✓ Loaded project boundary: {project_name}\")\n",
    "        print(f\"  Features: {len(gdf)}\")\n",
    "        print(f\"  Total Area: {gdf['area_ha'].sum():.2f} hectares\")\n",
    "        print(f\"  CRS: {gdf.crs}\")\n",
    "        \n",
    "        return gdf\n",
    "    else:\n",
    "        print(f\"❌ Boundary file not found for project: {project_name}\")\n",
    "        return None\n",
    "\n",
    "# Example: Load Mary Springs project boundary\n",
    "mary_springs_boundary = load_project_boundary(\"MARY_SPRINGS_EP_WA\", \"Mary springs boundary.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reference Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reference_data_for_boundary(boundary_gdf, buffer_distance_m=1000):\n",
    "    \"\"\"\n",
    "    Extract relevant reference data for a project boundary.\n",
    "    \n",
    "    Args:\n",
    "        boundary_gdf: GeoDataFrame with project boundary\n",
    "        buffer_distance_m: Buffer distance in meters for extraction\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted reference datasets\n",
    "    \"\"\"\n",
    "    if boundary_gdf is None:\n",
    "        return {}\n",
    "    \n",
    "    # Create buffer for data extraction\n",
    "    boundary_buffer = boundary_gdf.to_crs('EPSG:3577')  # Australian Albers for accurate buffering\n",
    "    boundary_buffer['geometry'] = boundary_buffer.geometry.buffer(buffer_distance_m)\n",
    "    boundary_buffer = boundary_buffer.to_crs('EPSG:7844')  # Back to GDA2020\n",
    "    \n",
    "    extracted_data = {}\n",
    "    \n",
    "    # Extract IBRA bioregions\n",
    "    ibra_path = reference_data / \"BOUNDARIES/BIOREGIONS_IBRA/IBRA7_subregions.shp\"\n",
    "    if ibra_path.exists():\n",
    "        ibra_gdf = gpd.read_file(ibra_path)\n",
    "        if ibra_gdf.crs != 'EPSG:7844':\n",
    "            ibra_gdf = ibra_gdf.to_crs('EPSG:7844')\n",
    "        \n",
    "        # Spatial intersection\n",
    "        ibra_intersect = gpd.overlay(ibra_gdf, boundary_buffer, how='intersection')\n",
    "        extracted_data['ibra_regions'] = ibra_intersect\n",
    "        print(f\"✓ Extracted {len(ibra_intersect)} IBRA subregions\")\n",
    "    \n",
    "    # Extract state boundaries\n",
    "    states_path = reference_data / \"BOUNDARIES/STATE_BOUNDARIES/STE_2021_AUST_GDA2020.shp\"\n",
    "    if states_path.exists():\n",
    "        states_gdf = gpd.read_file(states_path)\n",
    "        states_intersect = gpd.overlay(states_gdf, boundary_buffer, how='intersection')\n",
    "        extracted_data['states'] = states_intersect\n",
    "        print(f\"✓ Extracted {len(states_intersect)} state/territory boundaries\")\n",
    "    \n",
    "    # Extract LGA boundaries\n",
    "    lga_path = reference_data / \"BOUNDARIES/LGAs/LGA_2023_AUST_GDA2020.shp\"\n",
    "    if lga_path.exists():\n",
    "        lga_gdf = gpd.read_file(lga_path)\n",
    "        if lga_gdf.crs != 'EPSG:7844':\n",
    "            lga_gdf = lga_gdf.to_crs('EPSG:7844')\n",
    "        lga_intersect = gpd.overlay(lga_gdf, boundary_buffer, how='intersection')\n",
    "        extracted_data['lgas'] = lga_intersect\n",
    "        print(f\"✓ Extracted {len(lga_intersect)} Local Government Areas\")\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Extract reference data for Mary Springs (if loaded)\n",
    "if mary_springs_boundary is not None:\n",
    "    mary_springs_ref_data = extract_reference_data_for_boundary(mary_springs_boundary)\nelse:\n",
    "    print(\"Skipping reference data extraction - no boundary loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Raster Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_raster_data_for_boundary(boundary_gdf, raster_datasets=None):\n",
    "    \"\"\"\n",
    "    Analyze raster datasets for a project boundary.\n",
    "    \n",
    "    Args:\n",
    "        boundary_gdf: GeoDataFrame with project boundary\n",
    "        raster_datasets: Dictionary of raster dataset paths\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with raster analysis results\n",
    "    \"\"\"\n",
    "    if boundary_gdf is None:\n",
    "        return {}\n",
    "    \n",
    "    # Default raster datasets to analyze\n",
    "    if raster_datasets is None:\n",
    "        raster_datasets = {\n",
    "            'rainfall_lta': reference_data / \"CLIMATE/RAINFALL_LTA/LTA_rainfall.tif\",\n",
    "            'forest_productivity': reference_data / \"BIOMASS_NATIONAL/SITE_POTENTIAL_FPI_V2/fpi_lta_2019.tif\",\n",
    "            'soil_classification': reference_data / \"SOIL/AUSTRALIAN_SOIL_CLASSIFICATION/ASC_EV_C_P_AU_TRN_N.cog.tif\"\n",
    "        }\n",
    "    \n",
    "    analysis_results = {}\n",
    "    \n",
    "    for dataset_name, raster_path in raster_datasets.items():\n",
    "        if not raster_path.exists():\n",
    "            print(f\"⚠️  {dataset_name} not found: {raster_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Use rasterstats for zonal statistics\n",
    "            stats = rasterstats.zonal_stats(\n",
    "                boundary_gdf.geometry,\n",
    "                str(raster_path),\n",
    "                stats=['count', 'min', 'max', 'mean', 'median', 'std']\n",
    "            )\n",
    "            \n",
    "            # Combine statistics\n",
    "            combined_stats = {\n",
    "                'count': sum(s['count'] for s in stats if s['count'] is not None),\n",
    "                'min': min(s['min'] for s in stats if s['min'] is not None) if any(s['min'] is not None for s in stats) else None,\n",
    "                'max': max(s['max'] for s in stats if s['max'] is not None) if any(s['max'] is not None for s in stats) else None,\n",
    "                'mean': np.mean([s['mean'] for s in stats if s['mean'] is not None]) if any(s['mean'] is not None for s in stats) else None,\n",
    "                'median': np.median([s['median'] for s in stats if s['median'] is not None]) if any(s['median'] is not None for s in stats) else None,\n",
    "                'std': np.mean([s['std'] for s in stats if s['std'] is not None]) if any(s['std'] is not None for s in stats) else None\n",
    "            }\n",
    "            \n",
    "            analysis_results[dataset_name] = combined_stats\n",
    "            print(f\"✓ Analyzed {dataset_name}: mean = {combined_stats['mean']:.2f}\" if combined_stats['mean'] else f\"✓ Analyzed {dataset_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to analyze {dataset_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "# Analyze raster data for Mary Springs (if loaded)\n",
    "if mary_springs_boundary is not None:\n",
    "    mary_springs_raster_analysis = analyze_raster_data_for_boundary(mary_springs_boundary)\n",
    "    \n",
    "    # Create summary table\n",
    "    if mary_springs_raster_analysis:\n",
    "        analysis_df = pd.DataFrame(mary_springs_raster_analysis).T\n",
    "        analysis_df = analysis_df.round(2)\n",
    "        print(\"\\nRaster Analysis Summary:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(analysis_df)\nelse:\n",
    "    print(\"Skipping raster analysis - no boundary loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Carbon Potential Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_carbon_potential(boundary_gdf, species='Eucalyptus globulus', method='environmental_plantings'):\n",
    "    \"\"\"\n",
    "    Assess carbon sequestration potential for a project area.\n",
    "    \n",
    "    Args:\n",
    "        boundary_gdf: GeoDataFrame with project boundary\n",
    "        species: Primary tree species\n",
    "        method: FullCAM method type\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with carbon potential assessment\n",
    "    \"\"\"\n",
    "    if boundary_gdf is None:\n",
    "        return {}\n",
    "    \n",
    "    # Calculate total area in hectares\n",
    "    total_area_ha = boundary_gdf['area_ha'].sum()\n",
    "    \n",
    "    # Species-specific parameters (simplified estimates)\n",
    "    species_params = {\n",
    "        'Eucalyptus globulus': {\n",
    "            'growth_rate': 'fast',\n",
    "            'base_sequestration_tco2e_ha_yr': 8.5,\n",
    "            'max_height_m': 60,\n",
    "            'wood_density': 0.69\n",
    "        },\n",
    "        'Eucalyptus camaldulensis': {\n",
    "            'growth_rate': 'medium',\n",
    "            'base_sequestration_tco2e_ha_yr': 6.0,\n",
    "            'max_height_m': 45,\n",
    "            'wood_density': 0.75\n",
    "        },\n",
    "        'Pinus radiata': {\n",
    "            'growth_rate': 'fast',\n",
    "            'base_sequestration_tco2e_ha_yr': 7.5,\n",
    "            'max_height_m': 40,\n",
    "            'wood_density': 0.42\n",
    "        },\n",
    "        'Acacia melanoxylon': {\n",
    "            'growth_rate': 'medium',\n",
    "            'base_sequestration_tco2e_ha_yr': 5.0,\n",
    "            'max_height_m': 30,\n",
    "            'wood_density': 0.64\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get species parameters or default\n",
    "    params = species_params.get(species, {\n",
    "        'growth_rate': 'medium',\n",
    "        'base_sequestration_tco2e_ha_yr': 6.0,\n",
    "        'max_height_m': 25,\n",
    "        'wood_density': 0.55\n",
    "    })\n",
    "    \n",
    "    # Apply productivity modifier based on site conditions\n",
    "    productivity_modifier = 1.0  # Default\n",
    "    \n",
    "    # Try to get productivity from Forest Productivity Index\n",
    "    try:\n",
    "        fpi_path = reference_data / \"BIOMASS_NATIONAL/SITE_POTENTIAL_FPI_V2/fpi_lta_2019.tif\"\n",
    "        if fpi_path.exists():\n",
    "            fpi_stats = rasterstats.zonal_stats(\n",
    "                boundary_gdf.geometry,\n",
    "                str(fpi_path),\n",
    "                stats=['mean']\n",
    "            )\n",
    "            mean_fpi = np.mean([s['mean'] for s in fpi_stats if s['mean'] is not None])\n",
    "            if not np.isnan(mean_fpi):\n",
    "                productivity_modifier = mean_fpi / 100  # Convert percentage to factor\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Apply rainfall modifier\n",
    "    rainfall_modifier = 1.0\n",
    "    try:\n",
    "        rainfall_path = reference_data / \"CLIMATE/RAINFALL_LTA/LTA_rainfall.tif\"\n",
    "        if rainfall_path.exists():\n",
    "            rainfall_stats = rasterstats.zonal_stats(\n",
    "                boundary_gdf.geometry,\n",
    "                str(rainfall_path),\n",
    "                stats=['mean']\n",
    "            )\n",
    "            mean_rainfall = np.mean([s['mean'] for s in rainfall_stats if s['mean'] is not None])\n",
    "            if not np.isnan(mean_rainfall):\n",
    "                # Simple rainfall modifier (optimal around 800-1000mm)\n",
    "                if mean_rainfall < 400:\n",
    "                    rainfall_modifier = 0.6\n",
    "                elif mean_rainfall < 600:\n",
    "                    rainfall_modifier = 0.8\n",
    "                elif mean_rainfall > 1200:\n",
    "                    rainfall_modifier = 0.9\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Calculate carbon sequestration potential\n",
    "    base_rate = params['base_sequestration_tco2e_ha_yr']\n",
    "    modified_rate = base_rate * productivity_modifier * rainfall_modifier\n",
    "    \n",
    "    # Standard crediting period for different methods\n",
    "    crediting_periods = {\n",
    "        'environmental_plantings': 25,\n",
    "        'plantation_forestry': 30,\n",
    "        'human_induced_regeneration': 25\n",
    "    }\n",
    "    crediting_period = crediting_periods.get(method, 25)\n",
    "    \n",
    "    # Calculate totals\n",
    "    annual_sequestration = total_area_ha * modified_rate\n",
    "    total_sequestration = annual_sequestration * crediting_period\n",
    "    \n",
    "    assessment = {\n",
    "        'project_area_ha': round(total_area_ha, 2),\n",
    "        'species': species,\n",
    "        'method': method,\n",
    "        'crediting_period_years': crediting_period,\n",
    "        'base_sequestration_rate_tco2e_ha_yr': base_rate,\n",
    "        'productivity_modifier': round(productivity_modifier, 3),\n",
    "        'rainfall_modifier': round(rainfall_modifier, 3),\n",
    "        'adjusted_sequestration_rate_tco2e_ha_yr': round(modified_rate, 2),\n",
    "        'annual_sequestration_tco2e': round(annual_sequestration, 2),\n",
    "        'total_potential_sequestration_tco2e': round(total_sequestration, 2),\n",
    "        'assessment_date': pd.Timestamp.now().isoformat(),\n",
    "        'notes': [\n",
    "            'These are preliminary estimates only',\n",
    "            'Actual FullCAM modeling required for precise calculations',\n",
    "            'Site-specific conditions may significantly affect results'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return assessment\n",
    "\n",
    "# Assess carbon potential for Mary Springs (if loaded)\n",
    "if mary_springs_boundary is not None:\n",
    "    carbon_assessment = assess_carbon_potential(mary_springs_boundary, 'Eucalyptus globulus', 'environmental_plantings')\n",
    "    \n",
    "    print(\"Carbon Sequestration Assessment:\")\n",
    "    print(\"=\" * 40)\n",
    "    for key, value in carbon_assessment.items():\n",
    "        if key != 'notes':\n",
    "            print(f\"{key:<40}: {value}\")\n",
    "    \n",
    "    print(\"\\nNotes:\")\n",
    "    for note in carbon_assessment['notes']:\n",
    "        print(f\"  - {note}\")\nelse:\n",
    "    print(\"Skipping carbon assessment - no boundary loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization and Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_project_overview_map(boundary_gdf, reference_data_dict=None, title=\"Project Overview\"):\n",
    "    \"\"\"\n",
    "    Create an overview map of the project area with reference data.\n",
    "    \n",
    "    Args:\n",
    "        boundary_gdf: GeoDataFrame with project boundary\n",
    "        reference_data_dict: Dictionary with reference datasets\n",
    "        title: Map title\n",
    "    \n",
    "    Returns:\n",
    "        Folium map object\n",
    "    \"\"\"\n",
    "    if boundary_gdf is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate map center\n",
    "    bounds = boundary_gdf.total_bounds\n",
    "    center_lat = (bounds[1] + bounds[3]) / 2\n",
    "    center_lon = (bounds[0] + bounds[2]) / 2\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=10,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Add project boundary\n",
    "    folium.GeoJson(\n",
    "        boundary_gdf.to_json(),\n",
    "        style_function=lambda feature: {\n",
    "            'fillColor': '#ff7800',\n",
    "            'color': '#ff7800',\n",
    "            'weight': 3,\n",
    "            'fillOpacity': 0.3,\n",
    "        },\n",
    "        popup=folium.GeoJsonPopup(\n",
    "            fields=['area_ha'] if 'area_ha' in boundary_gdf.columns else [],\n",
    "            labels=['Area (ha):'] if 'area_ha' in boundary_gdf.columns else [],\n",
    "            aliases=['Area (ha):'] if 'area_ha' in boundary_gdf.columns else []\n",
    "        )\n",
    "    ).add_to(m)\n",
    "    \n",
    "    # Add reference data layers if provided\n",
    "    if reference_data_dict:\n",
    "        # Add IBRA regions\n",
    "        if 'ibra_regions' in reference_data_dict:\n",
    "            folium.GeoJson(\n",
    "                reference_data_dict['ibra_regions'].to_json(),\n",
    "                style_function=lambda feature: {\n",
    "                    'fillColor': '#lightblue',\n",
    "                    'color': '#blue',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.2,\n",
    "                },\n",
    "                popup=folium.GeoJsonPopup(\n",
    "                    fields=['REG_NAME_7'] if 'REG_NAME_7' in reference_data_dict['ibra_regions'].columns else [],\n",
    "                    labels=['IBRA Region:'] if 'REG_NAME_7' in reference_data_dict['ibra_regions'].columns else []\n",
    "                )\n",
    "            ).add_to(m)\n",
    "        \n",
    "        # Add state boundaries\n",
    "        if 'states' in reference_data_dict:\n",
    "            folium.GeoJson(\n",
    "                reference_data_dict['states'].to_json(),\n",
    "                style_function=lambda feature: {\n",
    "                    'fillColor': 'transparent',\n",
    "                    'color': '#red',\n",
    "                    'weight': 2,\n",
    "                    'fillOpacity': 0,\n",
    "                },\n",
    "                popup=folium.GeoJsonPopup(\n",
    "                    fields=['STE_NAME21'] if 'STE_NAME21' in reference_data_dict['states'].columns else [],\n",
    "                    labels=['State:'] if 'STE_NAME21' in reference_data_dict['states'].columns else []\n",
    "                )\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add title\n",
    "    title_html = f'''\n",
    "                 <h3 align=\"center\" style=\"font-size:20px\"><b>{title}</b></h3>\n",
    "                 '''\n",
    "    m.get_root().html.add_child(folium.Element(title_html))\n",
    "    \n",
    "    # Add layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Create overview map for Mary Springs (if loaded)\n",
    "if mary_springs_boundary is not None:\n",
    "    mary_springs_map = create_project_overview_map(\n",
    "        mary_springs_boundary, \n",
    "        mary_springs_ref_data if 'mary_springs_ref_data' in locals() else None,\n",
    "        \"Mary Springs Environmental Planting Project\"\n",
    "    )\n",
    "    mary_springs_map\nelse:\n",
    "    print(\"No boundary data loaded - cannot create map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Project Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_project_report(project_name, boundary_gdf, reference_data_dict=None, \n",
    "                          raster_analysis=None, carbon_assessment=None):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive project report.\n",
    "    \n",
    "    Args:\n",
    "        project_name: Name of the project\n",
    "        boundary_gdf: Project boundary GeoDataFrame\n",
    "        reference_data_dict: Dictionary with reference datasets\n",
    "        raster_analysis: Raster analysis results\n",
    "        carbon_assessment: Carbon assessment results\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with report data\n",
    "    \"\"\"\n",
    "    if boundary_gdf is None:\n",
    "        return {}\n",
    "    \n",
    "    report = {\n",
    "        'project_name': project_name,\n",
    "        'report_date': pd.Timestamp.now().isoformat(),\n",
    "        'total_area_ha': boundary_gdf['area_ha'].sum(),\n",
    "        'num_features': len(boundary_gdf),\n",
    "        'coordinate_system': str(boundary_gdf.crs)\n",
    "    }\n",
    "    \n",
    "    # Add reference data summary\n",
    "    if reference_data_dict:\n",
    "        report['reference_data'] = {}\n",
    "        \n",
    "        if 'ibra_regions' in reference_data_dict:\n",
    "            ibra = reference_data_dict['ibra_regions']\n",
    "            report['reference_data']['ibra_regions'] = {\n",
    "                'count': len(ibra),\n",
    "                'regions': ibra['REG_NAME_7'].unique().tolist() if 'REG_NAME_7' in ibra.columns else []\n",
    "            }\n",
    "        \n",
    "        if 'states' in reference_data_dict:\n",
    "            states = reference_data_dict['states']\n",
    "            report['reference_data']['states'] = {\n",
    "                'count': len(states),\n",
    "                'names': states['STE_NAME21'].unique().tolist() if 'STE_NAME21' in states.columns else []\n",
    "            }\n",
    "        \n",
    "        if 'lgas' in reference_data_dict:\n",
    "            lgas = reference_data_dict['lgas']\n",
    "            report['reference_data']['lgas'] = {\n",
    "                'count': len(lgas),\n",
    "                'names': lgas['LGA_NAME23'].unique().tolist()[:5] if 'LGA_NAME23' in lgas.columns else []  # Limit to first 5\n",
    "            }\n",
    "    \n",
    "    # Add raster analysis\n",
    "    if raster_analysis:\n",
    "        report['environmental_conditions'] = raster_analysis\n",
    "    \n",
    "    # Add carbon assessment\n",
    "    if carbon_assessment:\n",
    "        report['carbon_potential'] = carbon_assessment\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate report for Mary Springs (if data available)\n",
    "if mary_springs_boundary is not None:\n",
    "    mary_springs_report = generate_project_report(\n",
    "        \"Mary Springs Environmental Planting\",\n",
    "        mary_springs_boundary,\n",
    "        mary_springs_ref_data if 'mary_springs_ref_data' in locals() else None,\n",
    "        mary_springs_raster_analysis if 'mary_springs_raster_analysis' in locals() else None,\n",
    "        carbon_assessment if 'carbon_assessment' in locals() else None\n",
    "    )\n",
    "    \n",
    "    # Display report summary\n",
    "    print(f\"PROJECT REPORT: {mary_springs_report['project_name']}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Report Date: {mary_springs_report['report_date'][:19]}\")\n",
    "    print(f\"Total Area: {mary_springs_report['total_area_ha']:.2f} hectares\")\n",
    "    print(f\"Features: {mary_springs_report['num_features']}\")\n",
    "    print(f\"Coordinate System: {mary_springs_report['coordinate_system']}\")\n",
    "    \n",
    "    if 'reference_data' in mary_springs_report:\n",
    "        print(\"\\nREFERENCE DATA SUMMARY:\")\n",
    "        ref_data = mary_springs_report['reference_data']\n",
    "        if 'states' in ref_data:\n",
    "            print(f\"  States: {', '.join(ref_data['states']['names'])}\")\n",
    "        if 'ibra_regions' in ref_data:\n",
    "            print(f\"  IBRA Regions: {len(ref_data['ibra_regions']['regions'])} regions\")\n",
    "        if 'lgas' in ref_data:\n",
    "            print(f\"  Local Government Areas: {len(ref_data['lgas']['names'])} LGAs\")\n",
    "    \n",
    "    if 'carbon_potential' in mary_springs_report:\n",
    "        carbon = mary_springs_report['carbon_potential']\n",
    "        print(\"\\nCARBON POTENTIAL SUMMARY:\")\n",
    "        print(f\"  Species: {carbon['species']}\")\n",
    "        print(f\"  Method: {carbon['method']}\")\n",
    "        print(f\"  Annual Sequestration: {carbon['annual_sequestration_tco2e']} tCO2-e/year\")\n",
    "        print(f\"  Total Potential: {carbon['total_potential_sequestration_tco2e']} tCO2-e over {carbon['crediting_period_years']} years\")\nelse:\n",
    "    print(\"No boundary data loaded - cannot generate report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated comprehensive spatial analysis workflows for the T7 Shield GIS environment:\n",
    "\n",
    "### ✅ Capabilities Demonstrated:\n",
    "1. **Project Boundary Loading** - Automated detection and validation\n",
    "2. **Reference Data Extraction** - IBRA, states, LGAs integration\n",
    "3. **Raster Analysis** - Climate, soil, productivity assessment\n",
    "4. **Carbon Potential Assessment** - Species-based sequestration modeling\n",
    "5. **Interactive Mapping** - Professional visualization with Folium\n",
    "6. **Report Generation** - Comprehensive project reporting\n",
    "\n",
    "### 🎯 Next Steps:\n",
    "- Apply these workflows to your specific client projects\n",
    "- Customize carbon assessment parameters for different species\n",
    "- Integrate with FullCAM data preparation workflows\n",
    "- Develop project-specific analysis templates\n",
    "\n",
    "### 🔧 Professional Features:\n",
    "- **Error handling**: Robust error management throughout\n",
    "- **Coordinate systems**: Proper GDA2020 handling\n",
    "- **Performance**: Optimized for large datasets\n",
    "- **Modularity**: Reusable functions for different projects\n",
    "\n",
    "Your T7 Shield environment is ready for professional Australian forestry analysis! 🌳📊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t7_gis_professional",
   "language": "python",
   "name": "t7_gis_professional"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}